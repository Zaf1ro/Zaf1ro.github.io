<!DOCTYPE html>
<html lang="zh">
  <head>
    
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
<meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1">



  <meta name="description" content="HDFS Overview"/>




  <meta name="keywords" content="Distributed System," />


<meta name="google-site-verification" content="qy4gf0StWj627u-7aIP3WDCLBi3jPYXhm57UC7TUcok" />
<meta name="baidu-site-verification" content="XJoPG7ad2Z" />

<link rel="alternate" hreflang="x-default" href="https://zaf1ro.github.io/p/fa37.html" />
<link rel="alternate" hreflang="zh" href="https://zaf1ro.github.io/p/fa37.html" />




  <link rel="alternate" href="/default" title="Zaf1ro" >




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.jpeg?v=1.1" />



<link rel="canonical" href="https://zaf1ro.github.io/p/fa37.html"/>


<meta name="description" content="1. IntroductionHadoop Distributed File System(HDFS)首先是一个文件系统, 用于存储文件. 其使用传统的hierarchical file system(分层文件系统, HDFS中称为namespace): 我们可以创建, 删除文件, 也可以将一个文件从一个文件夹移动到另一个文件夹, 或重命名文件; 但HDFS的不同之处在于分布式: 其将多个机器集合">
<meta property="og:type" content="article">
<meta property="og:title" content="HDFS Overview">
<meta property="og:url" content="https://zaf1ro.github.io/p/fa37.html">
<meta property="og:site_name" content="Zaf1ro">
<meta property="og:description" content="1. IntroductionHadoop Distributed File System(HDFS)首先是一个文件系统, 用于存储文件. 其使用传统的hierarchical file system(分层文件系统, HDFS中称为namespace): 我们可以创建, 删除文件, 也可以将一个文件从一个文件夹移动到另一个文件夹, 或重命名文件; 但HDFS的不同之处在于分布式: 其将多个机器集合">
<meta property="og:locale">
<meta property="og:image" content="https://zaf1ro.github.io/images/System-Design/HDFS/1-1.png">
<meta property="og:image" content="https://zaf1ro.github.io/images/System-Design/HDFS/1-2.png">
<meta property="article:published_time" content="2022-04-11T20:38:10.000Z">
<meta property="article:modified_time" content="2024-08-20T16:43:04.039Z">
<meta property="article:tag" content="Distributed System">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://zaf1ro.github.io/images/System-Design/HDFS/1-1.png">


<link rel="stylesheet" type="text/css" href="/css/style.css?v=1.1" />




    <title>
HDFS Overview - Zaf1ro
</title>
  <meta name="generator" content="Hexo 6.3.0"></head>

  <body>
  <nav id="sidebar" class="active on-post">
    <div id="third">
      <div id="sidebar-title">
        <h1 id="sidebar-title-text">
            <a href="/." class="logo">Home</a>
        </h1>
      </div>
      <div id="google-search">
  <script async src="https://cse.google.com/cse.js?cx=009060789867951546370:v3hkcobeuh9"></script>
  <div class="gcse-search"></div>
</div>
      
  <div id="toc">
    <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-Introduction"><span class="toc-text">1. Introduction</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-Assumptions-and-Goals"><span class="toc-text">2. Assumptions and Goals</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-Architecture"><span class="toc-text">3. Architecture</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-NameNode"><span class="toc-text">4. NameNode</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-Secondary-NameNode"><span class="toc-text">4.1 Secondary NameNode</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-Checkpoint-Node"><span class="toc-text">4.2 Checkpoint Node</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3-Backup-Node"><span class="toc-text">4.3 Backup Node</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-DataNode"><span class="toc-text">5. DataNode</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-Data-Replication"><span class="toc-text">5.1 Data Replication</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-Replica-Placement"><span class="toc-text">5.2 Replica Placement</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-Replica-Selection"><span class="toc-text">5.3 Replica Selection</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-Write-File"><span class="toc-text">6. Write File</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-Read-File"><span class="toc-text">7. Read File</span></a></li></ol>
  </div>

    </div>
  </nav>

    <div id="page">
      <header id="masthead"><div class="site-header-inner">
  
  <button class="nav-mobile-button on-post" id="sidebarCollapse">
  
    <svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24"><path d="M24 6h-24v-4h24v4zm0 4h-24v4h24v-4zm0 8h-24v4h24v-4z"/></svg>
  </button>
  
  


  <nav id="nav-top">
    
      
      <ul id="menu-top" class="nav-top-items on-post">
      
        
          <li class="menu-item">
            <a target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/Zaf1ro">
              
              
                Github
              
            </a>
          </li>
        
      </ul>
    
  </nav>
</div>

      </header>
      <div id="content">
        
  <div class="primary">
    
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          HDFS Overview
        
      </h1>
      <time class="post-time">
          04/11/22
      </time>
    </header>

    <div class="post-content">
      <h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><p><strong>Hadoop Distributed File System</strong>(HDFS)首先是一个文件系统, 用于存储文件. 其使用传统的<strong>hierarchical file system</strong>(分层文件系统, HDFS中称为<strong>namespace</strong>): 我们可以创建, 删除文件, 也可以将一个文件从一个文件夹移动到另一个文件夹, 或重命名文件; 但HDFS的不同之处在于<strong>分布式</strong>: 其将多个机器集合为一个集群, 对外呈现出一个与传统文件系统无异的文件系统. HDFS与传统文件系统并不是对立的, HDFS集群中的单个机器仍使用传统文件系统, 并解放了单机的存储限制, 加入了<strong>fault-tolerant</strong>(容错).</p>
<h2 id="2-Assumptions-and-Goals"><a href="#2-Assumptions-and-Goals" class="headerlink" title="2. Assumptions and Goals"></a>2. Assumptions and Goals</h2><p>HDFS的设计理念基于以下假设&#x2F;目的:</p>
<ul>
<li>Hardware Failure(硬件故障): HDFS集群包含成百上千个机器, 每个机器都会存储数据. 假设一台机器出故障会导致整个系统瘫痪, 那么大部分时间下HDFS都无法工作, 因为机器越多, 出错概率越高. 因此, HDFS必须能快速检测故障, 并自动恢复.</li>
<li>Streaming Data Access(流式数据访问): 与运行在传统文件系统上的应用不同, 在HDFS上运行的应用需要<strong>流式数据访问</strong>: 由于HDFS的设计目的是<strong>批处理</strong>而不是<strong>用户交互</strong>, 因此数据吞吐量比数据访问延迟更重要.</li>
<li>Large Data Sets(大数据集): 在HDFS上运行的应用拥有超大数据集. HDFS中的一个文件通常是GB到TB大小. HDFS需支持上百万个这样的文件, 并通过增加机器数量来提高总数据带宽.</li>
<li>Simple Coherency Model(简单一致性模型): 在HDFS上运行的应用需要<strong>一次写入, 多次读取</strong>的文件访问模型: 文件一旦创建, 就不需要修改(可以追加或截断, 不能随机写). 这种模型简化了一致性问题, 让高吞吐量数据访问变为可能.</li>
<li>Moving Computation is Cheaper than Moving Data(移动计算比移动数据简单): 如果应用请求的<strong>计算</strong>在数据附近进行, 则计算的效率更高. 因此, 与其将数据移动到应用程序的位置, 不如将<strong>计算</strong>移动到数据的位置. HDFS为应用程序提供了接口, 让它们更靠近数据所在的位置.</li>
<li>Portability Across Heterogeneous Hardware and Software Platforms(跨异构硬件和软件平台的可移植性): HDFS可从一个平台移植到另一个平台, 因此很多应用都可以选择HDFS.</li>
</ul>
<p>HDFS的优点: 适合大数据(PB级数据, 百万文件), 无需特殊硬件(廉价机器), 高容错性(可防止文件丢失, 机器故障), 批处理, 高吞吐量(可横向拓展); 但缺点也很明显: 不支持低延迟数据访问, 写入后不可修改, 不支持并发写入, 不适合小文件存取.<br>因此适合HDFS的场景可以是:</p>
<ul>
<li>存储层: NoSQL HBase</li>
<li>中间层: 资源及数据管理, 如YARN, Sentry</li>
<li>计算层: MapReduce, Impala, Spark</li>
<li>封装工具: 基于MapReduce, Spark等计算引擎的工具, 如Hive, Mahout</li>
<li>应用层: 数据分析, 机器学习, 数据挖掘, 图像处理, 网络爬虫</li>
</ul>
<h2 id="3-Architecture"><a href="#3-Architecture" class="headerlink" title="3. Architecture"></a>3. Architecture</h2><ol>
<li>HDFS将文件切分为<strong>block</strong>(块), 默认块大小为128MB. 磁盘的块一般为512字节, HDFS之所以设置的非常大, 是为了让磁盘将大部分时间用于读取, 而不是查找块: 磁盘查找块的平均时长为10ms, 读取速度为100MB&#x2F;s, 因此HDFS读取某个块时, 查询只占1%的时间.</li>
<li>HDFS提供一个统一目录树(称为<strong>namespace</strong>), 客户端通过路径访问文件, 如: <code>hdfs://namenode:port/dir-a/dir-b/file.data</code></li>
<li>HDFS采用master&#x2F;slave架构, 集群中有一个master, 称为<strong>NameNode</strong>; 还有多个slave, 称为<strong>DataNode</strong>, 通常一个节点一个datanode. </li>
<li><strong>NameNode</strong>负责管理namespace(文件目录), 块映射, 副本数等, 统称为<strong>metadata</strong>(元数据)</li>
<li><strong>DataNode</strong>负责管理block</li>
<li>一个文件有多个副本(replica), 并存放在不同的datanode上</li>
<li>DataNode定期向namenode汇报block信息, NameNode负责保持副本数量</li>
<li>HDFS的内部机制对客户端公开, 客户端会直接读取或写入DataNode</li>
</ol>
<p><img src="/images/System-Design/HDFS/1-1.png" alt="HDFS Architecture"></p>
<h2 id="4-NameNode"><a href="#4-NameNode" class="headerlink" title="4. NameNode"></a>4. NameNode</h2><p>NameData主要有两项职责: 处理客户端的请求, 管理namespace(metadata). 元数据的存储机制如下:</p>
<ul>
<li>内存中有一份完整的元数据</li>
<li>磁盘中有一份元数据在某个时间点(checkpoint)的快照(fsimage)</li>
<li>一份记录所有文件修改的日志(edits)</li>
</ul>
<h3 id="4-1-Secondary-NameNode"><a href="#4-1-Secondary-NameNode" class="headerlink" title="4.1 Secondary NameNode"></a>4.1 Secondary NameNode</h3><p>当namenode启动时, 其会合并fsimage和edits文件(将fsimage更新至最新状态, 并清空edits). 但由于namenode只在启动时进行合并操作, 因此edits会变得非常大, 下次启动需花费很长时间进行合并. 由此诞生了<strong>Secondary NameNode</strong>, 其运行在另外一个节点, 定期从namenode读取并合并fsimage和edits. 并且, 如果NameNode崩溃, 可从secondary namenode恢复元数据.</p>
<h3 id="4-2-Checkpoint-Node"><a href="#4-2-Checkpoint-Node" class="headerlink" title="4.2 Checkpoint Node"></a>4.2 Checkpoint Node</h3><p><strong>Checkpoint node</strong>会定期从namenode读取fsimage和edits, 合并, 并返还给namenode, 其运行在一个单独的节点. Secondary NameNode和Checkpoint Node的差别在于: secondary namenode只负责合并, 方便namenode之后读取; checkpoint node则将合并后的元数据返还给namenode. 以下是其工作流程:</p>
<ol>
<li>Checkpoint NameNode向namenode发送请求, namenode将新的操作记录写入一个新的edits</li>
<li>NameNode向Checkpoint NameNode传输fsimage和旧的edits文件, checkpoint namenode合并两个文件, 产生一个新的fsimage</li>
<li>Checkpoint NameNode将新的fsimage传回NameNode</li>
<li>NameNode使用新的fsimage</li>
</ol>
<h3 id="4-3-Backup-Node"><a href="#4-3-Backup-Node" class="headerlink" title="4.3 Backup Node"></a>4.3 Backup Node</h3><p><strong>Backup Node</strong>在内存中维护最新的namespace, 与namenode保持同步. 但backup node无需从namenode下载fsimage和edits, 因为内存中已有完整的namespace, 因此在backup node创建checkpoint只需将内存中的namespace存入磁盘, 硬件要求上与namenode相同.<br>当前版本(Hadoop 3.3.2), 集群中只能有一个backup node, 但可以有多个checkpoint node. 如果使用backup node, 则可让namenode无需持久化存储, 让backup node承担持久化的责任.</p>
<h2 id="5-DataNode"><a href="#5-DataNode" class="headerlink" title="5. DataNode"></a>5. DataNode</h2><p><strong>DataNode</strong>有几项职责:</p>
<ul>
<li>处理来自客户端的读写请求</li>
<li>管理block(创建, 删除, 复制)</li>
<li>定期向namenode汇报自己持有的block信息</li>
<li>定期向namenode发送心跳</li>
</ul>
<p>如果datanode进程崩溃, 或网络故障导致无法与namenode通信, namenode不会立即判定该datanode死亡, 超过一定时间无心跳才认为datanode死亡.<br>DataNode只负责管理block, 无需知道哪些block属于哪些文件. Block被保存在本地文件系统, 且不会将所有block放在同一个文件夹中, 因为单个文件夹的文件数量过多会影响效率.<br>启动datanode时, 其会扫描本地文件系统中的所有block, 生成一个汇总列表(称为<strong>Blockreport</strong>), 并发送给namenode.</p>
<h3 id="5-1-Data-Replication"><a href="#5-1-Data-Replication" class="headerlink" title="5.1 Data Replication"></a>5.1 Data Replication</h3><p>单个文件会被切分为多个block, 因此除了最后一个block, 其余block都是相同大小. HDFS的容错基于block的<strong>replcation</strong>(复制), 因此datanode中的block也称为<strong>replica</strong>. 单个replica的数量称为<strong>replication factor</strong>(复制因子), 由于datanode不能持有同一block的多个replica, 因此该值也等同于datanode数量.<br><img src="/images/System-Design/HDFS/1-2.png" alt="Data Replication"></p>
<h3 id="5-2-Replica-Placement"><a href="#5-2-Replica-Placement" class="headerlink" title="5.2 Replica Placement"></a>5.2 Replica Placement</h3><p>如何放置replica决定了HDFS的容错和性能. HDFS采用<strong>rack-aware replica placement policy</strong>(机架感知副本放置策略)来提高带宽利用率, 可靠性和可用性.<br>大型HDFS集群的datanode会分布在多个机架上, 不同机架的节点(datanode)通过交换机通信. 在大多数情况下, 同一机架内的网络带宽大于不同机架间的网络带宽.<br>NameNode通过<strong>Hadoop Rack Awareness</strong>(Hadoop机架感知)来判断哪些datanode属于哪个<strong>rack ID</strong>(机架ID). 其中一种策略是: 每个replica放在不同的机架, 这样即使某个机架发生故障, 也不会丢失数据, 并且读取数据时可充分利用多个机架的带宽. 这种策略让负载平衡变得容易, 但写入时需将replica传输给多个机架.<br>一般情况下, HDFS的复制因子为3, 其放置策略为: 如果writer在datanode上, 则在该datanode上放置第一个replica; 否则选择与writer同机架的任意一个datanode. 第二个放在不同机架的datanode上, 最后一个放在与第二个datanode同机架的另一个datanode上. 该策略可减少机架间的写入流量. 由于机架出故障的概率小于单个节点出故障的概率, 因此不会降低可靠性和可用性. 但该策略不能提高读取带宽, 因为三份replica被放在两个机架上, 而不是三个. 该策略无法均匀分布replioca, 因为两个replica在同一个机架, 另一个replica在其他机架.<br>若复制因子大于3, 则随机放置第四个以及其他replica, 同时保持每个机架持有的replica数不超过一个上限: $(replicas - 1) &#x2F; racks + 2$</p>
<h3 id="5-3-Replica-Selection"><a href="#5-3-Replica-Selection" class="headerlink" title="5.3 Replica Selection"></a>5.3 Replica Selection</h3><p>为减少全局带宽的消耗和读取延迟, HDFS会让reader的请求尽可能靠近replica. 如果reader和replica处于同一机架, 则优先读取该replica; 若HDFS集群横跨多个数据中心, 则优先选择本地的数据中心.</p>
<h2 id="6-Write-File"><a href="#6-Write-File" class="headerlink" title="6. Write File"></a>6. Write File</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">conf.set(<span class="string">&quot;fs.defaultFS&quot;</span>,<span class="string">&quot;hdfs://node1:8020&quot;</span>);</span><br><span class="line"><span class="type">FileSystem</span> <span class="variable">fs</span> <span class="operator">=</span> FileSystem.get(conf);</span><br><span class="line"><span class="type">Path</span> <span class="variable">path</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/helloworld.txt&quot;</span>);</span><br><span class="line"><span class="type">FSDataOutputStream</span> <span class="variable">out</span> <span class="operator">=</span> fs.create(path);</span><br><span class="line"><span class="type">BufferedWriter</span> <span class="variable">bufferedWriter</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">BufferedWriter</span>(<span class="keyword">new</span> <span class="title class_">OutputStreamWriter</span>(out, StandardCharsets.UTF_8));</span><br><span class="line">bufferedWriter.write(<span class="string">&quot;Java API to write data in HDFS&quot;</span>);</span><br><span class="line">bufferedWriter.newLine();</span><br><span class="line">bufferedWriter.close();</span><br><span class="line">fs.close();</span><br></pre></td></tr></table></figure>
<p>以下是用户上传文件的流程:</p>
<ol>
<li>客户端调用<code>DistributedFileSystem</code>(FileSystem的子类)对象的<code>create()</code>函数, 返回一个<code>HdfsDataOutputStream</code>对象(其父类为<code>FSDataOutputStream</code>, <code>FSDataOutputStream</code>的父类为<code>java.io.OutputStream</code>). <code>FSDataOutputStream</code>封装了一个<code>DataOutputStream</code>对象.</li>
<li>创建<code>DFSOutputStream</code>的过程中, 会向namenode发起RPC连接, 请求创建文件. NameNode会检查文件是否存在, 路径问题, 权限问题, 配额问题, 加密问题, 网络问题等. 如果检查通过, NameNode会在edits留下一个记录, 并返回; 否则, 客户端抛出异常.</li>
<li><code>DFSOutputStream</code>的父类<code>FSOutputSummer</code>负责向<code>dataQueue</code>写入packet, 并唤醒<code>DataStreamer</code></li>
<li><code>DFSOutputStream</code>中包含一个<code>DataStreamer</code>对象, 其作为一个单独的线程(调用<code>run()</code>启动线程), 负责与namenode的RPC server通信, 以及向datanode传输数据.</li>
<li><code>DataStreamer</code>在向datanode发送数据前, 需要先向namenode申请block: <code>nextBlockOutputStream()</code>中调用namenode RPC server的<code>addBlock()</code>.</li>
<li>NameNode根据<strong>机架感知策略</strong>选择三个datanode, 并返回给<code>DataStreamer</code></li>
<li><code>DataStreamer</code>拥有一个数据队列(<code>dataQueue</code>), 其从队列中取出第一个packet, 并发送给第一个datanode. 这里需要区分三种文件分块:<ul>
<li>block: 每个文件都被切分为多个block, 默认为128MB</li>
<li>packet: 客户端与datanode传输数据的基本单元, 默认为64KB</li>
<li>chunk: 客户端与datanode传输数据时的校验值, 默认512字节<br>每个packet都包含一个chunk, 因此, 真实数据与校验值的比例为$128:1$(64KB:0.5KB)</li>
</ul>
</li>
<li><code>DataStreamer</code>通过socket与datanode的<code>DataXceiverServer</code>建立数据管道</li>
<li><code>DataXceiverServer</code>创建一个<code>DataXceiver</code>线程, 负责接收文件, 并传递给下游datanode</li>
<li>上游datanode负责接收下游datanode的写入结果, 并层层上传, 最后汇总并上传给<code>DataStreamer</code></li>
<li><code>DataStreamer</code>发送packet后, 会将该packet移至<code>ackQueue</code>, 收到ACK后从<code>ackQueue</code>中移除; 如果超时, 则认为写入失败, 将packet移回到<code>dataQueue</code>(datanode之间的传输同理)</li>
<li>如果无法与datanode建立管道, 则向namenode申请放弃该block, 并重新申请block和datanode列表</li>
<li>如果成功建立数据管道, 但传输失败:<ul>
<li>当datanode检测到错误(如校验失败), 会关闭所有socket连接</li>
<li>当客户端检测到传输失败(如超时), 会向其他datanode建立新的管道</li>
</ul>
</li>
</ol>
<h2 id="7-Read-File"><a href="#7-Read-File" class="headerlink" title="7. Read File"></a>7. Read File</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">conf.set(<span class="string">&quot;fs.defaultFS&quot;</span>,<span class="string">&quot;hdfs://node1:8020&quot;</span>);</span><br><span class="line"><span class="type">FileSystem</span> <span class="variable">fs</span> <span class="operator">=</span> FileSystem.get(conf);</span><br><span class="line"><span class="type">Path</span> <span class="variable">path</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/helloworld.txt&quot;</span>);</span><br><span class="line"><span class="type">FSDataInputStream</span> <span class="variable">in</span> <span class="operator">=</span> fs.open(inFile);</span><br><span class="line"><span class="type">BufferedReader</span> <span class="variable">buff</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">BufferedReader</span>(<span class="keyword">new</span> <span class="title class_">InputStreamReader</span>(in));</span><br><span class="line"><span class="type">String</span> <span class="variable">s</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line"><span class="keyword">while</span> ((s = buff.readLine()) != <span class="literal">null</span>) &#123;</span><br><span class="line">  System.out.println(s);</span><br><span class="line">&#125;</span><br><span class="line">buff.close();</span><br><span class="line">in.close();</span><br><span class="line">fs.close();</span><br></pre></td></tr></table></figure>
<p>以下是用户读取文件的流程:</p>
<ol>
<li>与写入数据相同, 客户端调用<code>DistributedFileSystem</code>(FileSystem的子类)对象的<code>open()</code>函数, 返回一个<code>HdfsDataInputStream</code>对象(其父类为<code>FSDataInputStream</code>, <code>FSDataInputStream</code>的父类为<code>java.io.InputStream</code>). <code>FSDataInputStream</code>封装了一个<code>DFSInputStream</code>对象.</li>
<li>创建<code>DFSInputStream</code>的过程中, 会向namenode发起RPC连接, 并远程调用<code>getBlockLocations()</code>来获取该文件的所有block信息. NameNode借助namespace获得文件对应的block信息, 并根据客户端的位置对datanode进行排序, 最后返还给<code>LocatedBlocks</code>对象</li>
<li><code>LocatedBlocks</code>包含一个<code>LocatedBlock</code>列表, <code>LocatedBlock</code>对象主要包含以下信息:<ul>
<li>b: block的信息, 包含block的字节数, block的ID等</li>
<li>offset: block第一个字节在文件中的偏移量</li>
<li>locs: block处于哪些datanode上</li>
</ul>
</li>
<li>客户端调用<code>FSDataInputStream</code>的<code>opne()</code>函数读取文件, 其会调用<code>DFSInputStream</code>的<code>read()</code>函数</li>
<li>HDFS中, 读取通常需要经过datanode, 因此客户端请求文件时, 需通过TCP socket与datanode连接, 并让datanode发送给客户端; 但如果客户端与数据处于同一位置, 可绕过datanode, 直接访问数据, 称为<strong>short-circuit</strong>(短路)</li>
<li>DataNode的DataXceiverServer线程会一直等待请求, 一旦有新的请求, 就创建一个守护线程<code>DataXceiver</code>用于处理请求. 每个请求都有一个<strong>操作码</strong>(Op), 用于区分请求的类型(读, 写, 复制等).</li>
<li>通常从磁盘读取数据时, 首先内核读出数据, 放入kernel space, 然后从kernel space传递给user space的应用buffer, 再从buffer移动到kernel space的socket buffer; HDFS使用<code>java.nio.channels.FileChannel</code>的<code>transferTo()</code>支持Linux系统上的<strong>零拷贝</strong>, 让磁盘里的数据不经过user space, 直接传给socket buffer.</li>
<li>客户端 会将接收到的packet以追加的模式合并为目标文件, 并写入本地</li>
</ol>

    </div>

    <footer class="post-footer">
      
      <div class="post-tags">
        
          <a href="/tags/Distributed-System/">Distributed System</a>
        
      </div>
      

      
      
  <nav class="post-nav">
    
      <a class="prev" href="/p/245f.html">
        <i class="icon-left"></i>
        <span class="prev-text nav-default">HDFS Recovery Process</span>
        <span class="prev-text nav-mobile">Prev</span>
      </a>
    
    
      <a class="next" href="/p/da42.html">
        <span class="next-text nav-default">Consistency and Consensus</span>
        <span class="prev-text nav-mobile">Next</span>
        <i class="icon-right"></i>
      </a>
    
  </nav>

      
    </footer>
  </article>

  </div>
  
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js?config=TeX-MML-AM_CHTML"></script>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    showProcessingMessages: true,
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        processEscapes: false,
        skipTags: ["script","noscript","style","textarea"]
    },
    TeX: {
        Macros:{
            Arr: ["\\{ #1 \\}", 1],
            fi: "{f\\,\\!_i}",
            SS: ["{#1\\:\\!_#2}",2],
            SUBx: ["{\\:\\!_#1}",1],
            EXPx: ["{\\;\\!^#1}",1],
            Ss: ["{#1\\,\\!_#2}",2],
            subx: ["{\\,\\!_#1}",1]
        }
    }
});
</script>


      </div>
    </div>

    
<script type="text/javascript">
  var disqus_shortname = 'zaf1ro';
  var disqus_identifier = 'p/fa37.html';
  var disqus_title = "HDFS Overview";

  var disqus = {
    load : function disqus(){
        if(typeof DISQUS !== 'object') {
          (function () {
          var s = document.createElement('script'); s.async = true;
          s.type = 'text/javascript';
          s.src = '//' + disqus_shortname + '.disqus.com/embed.js';
          (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
          }());
          $('#load-disqus').remove(); ///加载后移除按钮
        }
    }
  }

  
    var disqus_config = function () {
        this.page.url = disqus_url;
        this.page.identifier = disqus_identifier;
        this.page.title = disqus_title;
    };
  

</script>



    




  
    <script type="text/javascript" src="/lib/jquery/jquery-3.6.0.min.js"></script>
  

  

    
    <script type="text/javascript">
(function(){"use strict";var Theme={};Theme.backToTop={register:function(){var $backToTop=$('#back-to-top');$(window).scroll(function(){if($(window).scrollTop()>100){$backToTop.fadeIn(1000)}else{$backToTop.fadeOut(1000)}});$backToTop.click(function(){$('body').animate({scrollTop:0})})}};Theme.fancybox={register:function(){if($.fancybox){$('.post').each(function(){$(this).find('img').each(function(){$(this).wrap('<a class="fancybox" href="'+this.src+'" title="'+this.alt+'"></a>')})});$('.fancybox').fancybox({openEffect:'elastic',closeEffect:'elastic'})}}};this.Theme=Theme}.call(this));
</script>

<script type="text/javascript">
$(document).ready(function(){if(themeConfig.fancybox.enable){Theme.fancybox.register()}Theme.backToTop.register()});
</script>
    
<script type="text/javascript">
var themeConfig = {
  fancybox: {
    enable: false
  },
};
</script>

    <script>
    $('table').wrap('<div style="overflow-x: auto;"></div>');
</script>
    
    <script>
$(document).ready(function () {
    $('#sidebarCollapse').on('click', function(){
        $('#sidebar').toggleClass('active');
    });

    $('#toc ol li a').on('click', function(){
        $('#sidebar').toggleClass('active');
    });
});
</script>
  </body>
</html>
