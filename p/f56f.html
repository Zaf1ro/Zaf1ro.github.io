<!DOCTYPE html>
<html lang="zh">
  <head>
    
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
<meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1">



  <meta name="description" content="Volumes"/>




  <meta name="keywords" content="K8s," />


<meta name="google-site-verification" content="qy4gf0StWj627u-7aIP3WDCLBi3jPYXhm57UC7TUcok" />
<meta name="baidu-site-verification" content="XJoPG7ad2Z" />

<link rel="alternate" hreflang="x-default" href="https://zaf1ro.github.io/p/f56f.html" />
<link rel="alternate" hreflang="zh" href="https://zaf1ro.github.io/p/f56f.html" />




  <link rel="alternate" href="/default" title="Zaf1ro" >




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.jpeg?v=1.1" />



<link rel="canonical" href="https://zaf1ro.github.io/p/f56f.html"/>


<meta name="description" content="1. Introduction由于每个container都有独立的filesystem, 会带来两个问题:  即使两个container位于同一pod, 它们也无法获取彼此的文件 当container重启时, 重启后的container无法获取之前的无法  因此我们需要一种方法来让两个container(同一pod的两个container, 或重启前与重启后的container)共享文件: vol">
<meta property="og:type" content="article">
<meta property="og:title" content="Volumes">
<meta property="og:url" content="https://zaf1ro.github.io/p/f56f.html">
<meta property="og:site_name" content="Zaf1ro">
<meta property="og:description" content="1. Introduction由于每个container都有独立的filesystem, 会带来两个问题:  即使两个container位于同一pod, 它们也无法获取彼此的文件 当container重启时, 重启后的container无法获取之前的无法  因此我们需要一种方法来让两个container(同一pod的两个container, 或重启前与重启后的container)共享文件: vol">
<meta property="og:locale">
<meta property="og:image" content="https://zaf1ro.github.io/images/Kubernetes/vol-1-1.png">
<meta property="og:image" content="https://zaf1ro.github.io/images/Kubernetes/vol-1-2.png">
<meta property="og:image" content="https://zaf1ro.github.io/images/Kubernetes/vol-2-1.png">
<meta property="og:image" content="https://zaf1ro.github.io/images/Kubernetes/vol-3-1.png">
<meta property="og:image" content="https://zaf1ro.github.io/images/Kubernetes/vol-4-1.png">
<meta property="og:image" content="https://zaf1ro.github.io/images/Kubernetes/vol-5-1.png">
<meta property="og:image" content="https://zaf1ro.github.io/images/Kubernetes/vol-5-2.png">
<meta property="og:image" content="https://zaf1ro.github.io/images/Kubernetes/vol-5-3.png">
<meta property="og:image" content="https://zaf1ro.github.io/images/Kubernetes/vol-5-4.png">
<meta property="og:image" content="https://zaf1ro.github.io/images/Kubernetes/vol-6-1.png">
<meta property="article:published_time" content="2019-10-24T16:57:55.000Z">
<meta property="article:modified_time" content="2025-02-18T22:08:33.536Z">
<meta property="article:tag" content="K8s">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://zaf1ro.github.io/images/Kubernetes/vol-1-1.png">


<link rel="stylesheet" type="text/css" href="/css/style.css?v=1.1" />




    <title>
Volumes - Zaf1ro
</title>
  <meta name="generator" content="Hexo 6.3.0"></head>

  <body>
  <nav id="sidebar" class="active on-post">
    <div id="third">
      <div id="sidebar-title">
        <h1 id="sidebar-title-text">
            <a href="/." class="logo">Home</a>
        </h1>
      </div>
      <div id="google-search">
  <script async src="https://cse.google.com/cse.js?cx=009060789867951546370:v3hkcobeuh9"></script>
  <div class="gcse-search"></div>
</div>
      
  <div id="toc">
    <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-Introduction"><span class="toc-text">1. Introduction</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-Use-Volumes-to-Share-Data-between-Containers"><span class="toc-text">2. Use Volumes to Share Data between Containers</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-emptyDir-Volume"><span class="toc-text">2.1 emptyDir Volume</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-gitRepo-Volume"><span class="toc-text">2.2 gitRepo Volume</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-Access-Files-on-the-Worker-Node-s-Filesystem"><span class="toc-text">3. Access Files on the Worker Node&#39;s Filesystem</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-Persistent-Storage"><span class="toc-text">4. Persistent Storage</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-GCP-Persistent-Disk"><span class="toc-text">4.1 GCP Persistent Disk</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-AWS-Persistent-Data"><span class="toc-text">4.2 AWS Persistent Data</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3-NFS-Volume"><span class="toc-text">4.3 NFS Volume</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-Decouple-Pods-from-the-Underlying-Storage-Technology"><span class="toc-text">5. Decouple Pods from the Underlying Storage Technology</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-Claim-a-PersistentVolume"><span class="toc-text">5.1 Claim a PersistentVolume</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-Claiming-a-PersistentVolume-by-creating-a-PersistentVolumeClaim"><span class="toc-text">5.2 Claiming a PersistentVolume by creating a PersistentVolumeClaim</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-Use-a-PersistentVolumeClaim"><span class="toc-text">5.3 Use a PersistentVolumeClaim</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-4-Recycle-PersistentVolume"><span class="toc-text">5.4 Recycle PersistentVolume</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-Dynamic-Provisioning-of-PersistentVolume"><span class="toc-text">6. Dynamic Provisioning of PersistentVolume</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#6-1-Define-a-StorageClass"><span class="toc-text">6.1 Define a StorageClass</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-2-Request-the-StorageClass-in-a-PersistentVolumeClaim"><span class="toc-text">6.2 Request the StorageClass in a PersistentVolumeClaim</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-3-Dynamic-provisioning-without-specifying-a-StorageClass"><span class="toc-text">6.3 Dynamic provisioning without specifying a StorageClass</span></a></li></ol></li></ol>
  </div>

    </div>
  </nav>

    <div id="page">
      <header id="masthead"><div class="site-header-inner">
  
  <button class="nav-mobile-button on-post" id="sidebarCollapse">
  
    <svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24"><path d="M24 6h-24v-4h24v4zm0 4h-24v4h24v-4zm0 8h-24v4h24v-4z"/></svg>
  </button>
  
  


  <nav id="nav-top">
    
      
      <ul id="menu-top" class="nav-top-items on-post">
      
        
          <li class="menu-item">
            <a target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/Zaf1ro">
              
              
                Github
              
            </a>
          </li>
        
      </ul>
    
  </nav>
</div>

      </header>
      <div id="content">
        
  <div class="primary">
    
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          Volumes
        
      </h1>
      <time class="post-time">
          10/24/19
      </time>
    </header>

    <div class="post-content">
      <h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><p>由于每个container都有独立的filesystem, 会带来两个问题:</p>
<ul>
<li>即使两个container位于同一pod, 它们也无法获取彼此的文件</li>
<li>当container重启时, 重启后的container无法获取之前的无法</li>
</ul>
<p>因此我们需要一种方法来让两个container(同一pod的两个container, 或重启前与重启后的container)共享文件: volume并不是k8s的一种resource, 而是作为pod的一个组成部分. Volume具有以下属性:</p>
<ul>
<li>无法通过YAML创建一个单独的volume</li>
<li>Pod创建时会自动生成volume, pod被销毁时也会自动删除volume</li>
<li>若pod内有多个container, 则这些container共享该volume</li>
<li>由于volume的生存周期与volume绑定, 因此重启container不影响volume, 且重启后的container依然可看到重启前container写入的文件</li>
</ul>
<p>需要注意的是, 只有volume被mount到container上时, container才能访问volume. 假设一个pod中有三个container, 分别为:</p>
<ul>
<li>web server: 负责从<code>/var/htdocs/</code>路径中读取HTML文件, 并将日志存入<code>/var/logs/</code>路径中</li>
<li>content agent: 负责生成HTML文件并保存到<code>/var/html/</code>路径中</li>
<li>log rotator: 负责处理<code>/var/logs/</code>路径中的日志文件</li>
</ul>
<p>由于每个container各自拥有独立的filesystem, 因此web server生成的日志无法被log rotator获取, content agent生成的HTML也无法被web server获取:<br><img src="/images/Kubernetes/vol-1-1.png" alt="Three containers of the same pod without shared storage"></p>
<p>添加两个volume后, container就可以通过volume共享文件:<br><img src="/images/Kubernetes/vol-1-2.png" alt="Three containers sharing two volumes mounted at various mount paths"></p>
<p>K8s提供了多种volume类型:</p>
<ul>
<li>emptyDir: 生成一个空文件夹, 用于存放临时数据</li>
<li>hostPath: 将node上的文件系统mount到pod中</li>
<li>gitRepo: volume中的内容由git repository初始化</li>
<li>nfs: 将NFS mount到pod中</li>
<li>gcePersistentDisk, awsElasticBlockStore, azureDisk: 将云服务提供商的存储服务mount到pod中</li>
<li>cinder, cephfs, iscsi, flocker, glusterfs, quobyte, rbd, flexVolume, vsphereVolume, photonPersistentDisk, scaleIO: 将不同类型的网络存储服务mount到pod中</li>
<li>configMap, secret, downwardAPI: 将k8s资源和cluster信息mount到pod中</li>
<li>persistentVolumeClaim: 将persistent volume(PV)中的文件mount到pod中,</li>
</ul>
<p>一个pod中可使用多个不同类型的volume, pod中的container需mount每一个需要使用的volume.</p>
<h2 id="2-Use-Volumes-to-Share-Data-between-Containers"><a href="#2-Use-Volumes-to-Share-Data-between-Containers" class="headerlink" title="2. Use Volumes to Share Data between Containers"></a>2. Use Volumes to Share Data between Containers</h2><h3 id="2-1-emptyDir-Volume"><a href="#2-1-emptyDir-Volume" class="headerlink" title="2.1 emptyDir Volume"></a>2.1 emptyDir Volume</h3><p><code>emptyDir</code>是最简单的volume类型, 其会提供一个空文件夹, container可向volume中写入或读取文件, 也可实现不同container共享文件. 但缺陷也明显: 由于emptyDir的生存周期与pod绑定, 因此pod删除后emptyDir也会消失.<br>假设在一个pod中运行两个container, 一个由Nginx运行的web server, 一个fortune命令(定期将一个随机字段写入文件中)执行的content agent. Pod的YAML文件如下:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">fortune</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">luksa/fortune</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">html-generator</span></span><br><span class="line">    <span class="attr">volumeMounts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">html</span></span><br><span class="line">      <span class="attr">mountPath:</span> <span class="string">/var/htdocs</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">nginx:alpine</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">web-server</span></span><br><span class="line">    <span class="attr">volumeMounts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">html</span></span><br><span class="line">      <span class="attr">mountPath:</span> <span class="string">/usr/share/nginx/html</span></span><br><span class="line">      <span class="attr">readOnly:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">html</span></span><br><span class="line">    <span class="attr">emptyDir:</span> &#123;&#125;</span><br></pre></td></tr></table></figure>
<p>上述pod中存在两个container:</p>
<ul>
<li>Nginx默认读取<code>/usr/share/nginx/html</code>目录中的HTML文件, 因此将volume挂载到该路径上</li>
<li>fortune脚本会每隔10秒向<code>/var/htdocs/index.html</code>文件中写入随机字段, 因此将volume挂载到<code>/var/htdocs</code>上</li>
</ul>
<p>这样nginx就可从HTML文件中读取到fortune写入的数据, nginx再将更新后的数据发送给用户. emptyDir默认将数据保存在node的磁盘上, 因此文件读写速度与node上的磁盘类型相关. K8s支持修改emptyDir的存储媒介, 如内存:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">volumes:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">html</span></span><br><span class="line">  <span class="attr">emptyDir:</span></span><br><span class="line">  <span class="attr">medium:</span> <span class="string">Memory</span></span><br></pre></td></tr></table></figure>

<h3 id="2-2-gitRepo-Volume"><a href="#2-2-gitRepo-Volume" class="headerlink" title="2.2 gitRepo Volume"></a>2.2 gitRepo Volume</h3><p>gitRepo作为emptyDir的增强版, 会先创建一个空的volume, 再从git repository复制数据到volume中, 流程如下:<br><img src="/images/Kubernetes/vol-2-1.png" alt="A gitRepo volume is an emptyDir volume initially populated with the contents of a Git repository"></p>
<p>需要注意的是, gitRepo被创建后, 若其他开发者向该仓库push commit, volume中的数据不会同步更新; 但若pod由ReplicationController管理, 则pod被删除后, 新产生的pod会拥有最新的commit数据.<br>假设一个git repo中存有HTML文件, web server会从该repo中读取HTML, pod的YAML文件如下:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">gitrepo-volume-pod</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">nginx:alpine</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">web-server</span></span><br><span class="line">    <span class="attr">volumeMounts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">html</span></span><br><span class="line">      <span class="attr">mountPath:</span> <span class="string">/usr/share/nginx/html</span></span><br><span class="line">      <span class="attr">readOnly:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">80</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">html</span></span><br><span class="line">    <span class="attr">gitRepo:</span></span><br><span class="line">      <span class="attr">repository:</span> <span class="string">https://github.com/luksa/kubia-website-example.git</span></span><br><span class="line">      <span class="attr">revision:</span> <span class="string">master</span></span><br><span class="line">      <span class="attr">directory:</span> <span class="string">.</span> </span><br></pre></td></tr></table></figure>
<p>当创建该pod时, k8s会先创建一个空的文件夹, 并将git repo中的数据clone到volume中. 若未将<code>directory</code>设置为<code>.</code>, 则会将repo中的数据clone到<code>kubia-website-example</code>文件夹中.<br>虽然gitRepo不提供同步功能, 但Docker Hub上有很多container image实现该功能, 这类container被称为<strong>sidecar container</strong>. sidecar container 虽然与web-server container处于同一Pod, 但却为辅助web-server运行而存在.<br>gitRepo还存在一个缺陷: 不支持从private git repo中复制数据, 因为gitRepo不支持SSH协议; 若需要从private git repo复制数据, 还需要其他sidebar container的帮助. 需要注意的是, gitRepo与emptyDir的生存周期相同, 都会在pod被删除后一并删除.</p>
<h2 id="3-Access-Files-on-the-Worker-Node-s-Filesystem"><a href="#3-Access-Files-on-the-Worker-Node-s-Filesystem" class="headerlink" title="3. Access Files on the Worker Node&#39;s Filesystem"></a>3. Access Files on the Worker Node&#39;s Filesystem</h2><p>一般情况下, pod无需关心在哪个node上运行; 但有些pod(如DaemonSet管理的pod)需要读取node上的文件, 或使用node的文件系统访问node的设备. K8s提供了<strong>hostPath</strong>将node上的某个路径mount到container的指定路径:<br><img src="/images/Kubernetes/vol-3-1.png" alt="A hostPath volume mounts a file or directory on the worker node into the container’s filesystem"></p>
<p>下面YAML文件创造了一个pod, 将node的<code>/data</code>文件夹mount到<code>test-container</code>的<code>/test-pd</code>. 添加修改或删除container中<code>/test-pd</code>内文件都会同步到node上的<code>/data</code>, 反之同理.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">test-pd</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">k8s.gcr.io/test-webserver</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">test-container</span></span><br><span class="line">    <span class="attr">volumeMounts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">mountPath:</span> <span class="string">/test-pd</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">test-volume</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">test-volume</span></span><br><span class="line">    <span class="attr">hostPath:</span></span><br><span class="line">      <span class="attr">path:</span> <span class="string">/data</span></span><br><span class="line">      <span class="attr">type:</span> <span class="string">Directory</span></span><br></pre></td></tr></table></figure>
<p>相对于emptyDir和gitRepo, hostPath提供了persistent storage(可持续存储), 意味着pod被删除后volume中的数据不会消失, 只要pod被部署到相同node上, 就可以重新访问该数据. 该volume的缺陷也很明显: 一旦将pod重新部署到其他node, 则无法访问数据, 因此不推荐将hostPath作为一个数据库应用的存储方式, 只有需要访问node的系统文件时再使用hostPath.</p>
<h2 id="4-Persistent-Storage"><a href="#4-Persistent-Storage" class="headerlink" title="4. Persistent Storage"></a>4. Persistent Storage</h2><p>若pod需要将数据存储到磁盘上, 且被重新部署到其他node上时仍需访问该数据, 则上述volume皆无法实现, 因为volume的生存周期不能与pod绑定, volume的存储位置不能与node绑定. 不同的云服务提供商提供了不同的NAS(network-attached storage)来解决该问题. 以下会以GCP(Google Cloud Platform)和AWS(Amazon Web Services)为例, 部署包含MongoDB的pod.</p>
<h3 id="4-1-GCP-Persistent-Disk"><a href="#4-1-GCP-Persistent-Disk" class="headerlink" title="4.1 GCP Persistent Disk"></a>4.1 GCP Persistent Disk</h3><p>GCP提供自家的persistent disk. 该persistent disk不属于任何namespace或cluster, 只与zone绑定, 因此cluster必须与persistent disk处于同一zone. 运行gcloud命令可查看当前所有cluster所在的zone:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ gcloud container clusters list</span><br><span class="line">NAME  ZONE           MASTER_VERSION MASTER_IP ...</span><br><span class="line">kubia europe-west1-b 1.2.5          104.155.84.137 ...</span><br></pre></td></tr></table></figure>
<p>可以发现kubia位于<code>europe-west1-b</code>, 因此我们需要在该zone创建GCE persistent disk.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ gcloud compute disks create --size=1GiB --zone=europe-west1-b mongodb</span><br><span class="line">NAME    ZONE           SIZE_GB TYPE        STATUS</span><br><span class="line">mongodb europe-west1-b 1       pd-standard READY</span><br></pre></td></tr></table></figure>
<p>上述命令在<code>europe-west1-b</code>创造了一个1Gb大小的persistent disk, 现在可创造pod并使用该persistent disk:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">mongodb</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">mongodb-data</span></span><br><span class="line">    <span class="attr">gcePersistentDisk:</span></span><br><span class="line">      <span class="attr">pdName:</span> <span class="string">mongodb</span></span><br><span class="line">      <span class="attr">fsType:</span> <span class="string">ext4</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">mongo</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">mongodb</span></span><br><span class="line">    <span class="attr">volumeMounts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">mongodb-data</span></span><br><span class="line">      <span class="attr">mountPath:</span> <span class="string">/data/db</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">27017</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">TCP</span></span><br></pre></td></tr></table></figure>
<p>通过标注gcePersistentDisk可将GCE persistent disk添加到pod中, 即使该pod被移除, persistent disk中的数据也不会受影响:<br><img src="/images/Kubernetes/vol-4-1.png" alt="A pod with a single container running MongoDB, which mounts a volume referencing an external GCE Persistent Disk"></p>
<h3 id="4-2-AWS-Persistent-Data"><a href="#4-2-AWS-Persistent-Data" class="headerlink" title="4.2 AWS Persistent Data"></a>4.2 AWS Persistent Data</h3><p>AWS和Azure也提供了persistent disk, 步骤与GCP的NAS相同: 在cluster所在的zone中创建volume, 再在pod中声明该volume:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">aws ec2 create-volume --size 1 --availability-zone us-east-1a</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">&quot;AvailabilityZone&quot;</span>: <span class="string">&quot;us-east-1a&quot;</span>,</span><br><span class="line">  <span class="string">&quot;Tags&quot;</span>: [],</span><br><span class="line">  <span class="string">&quot;Encrypted&quot;</span>: <span class="literal">false</span>,</span><br><span class="line">  <span class="string">&quot;VolumeType&quot;</span>: <span class="string">&quot;gp2&quot;</span>,</span><br><span class="line">  <span class="string">&quot;VolumeId&quot;</span>: <span class="string">&quot;vol-1234567890abcdef0&quot;</span>,</span><br><span class="line">  <span class="string">&quot;State&quot;</span>: <span class="string">&quot;creating&quot;</span>,</span><br><span class="line">  <span class="string">&quot;Iops&quot;</span>: 240,</span><br><span class="line">  <span class="string">&quot;SnapshotId&quot;</span>: <span class="string">&quot;&quot;</span>,</span><br><span class="line">  <span class="string">&quot;CreateTime&quot;</span>: <span class="string">&quot;YYYY-MM-DDTHH:MM:SS.000Z&quot;</span>,</span><br><span class="line">  <span class="string">&quot;Size&quot;</span>: 80</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">mongodb</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">mongodb-data</span></span><br><span class="line">    <span class="attr">awsElasticBlockStore:</span></span><br><span class="line">    <span class="attr">volumeId:</span> <span class="string">vol-1234567890abcdef0</span></span><br><span class="line">      <span class="attr">fsType:</span> <span class="string">ext4</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">...</span></span><br></pre></td></tr></table></figure>

<h3 id="4-3-NFS-Volume"><a href="#4-3-NFS-Volume" class="headerlink" title="4.3 NFS Volume"></a>4.3 NFS Volume</h3><p>如果选择自己搭建k8s cluster, 也可以自己配置persistent storage. 例如, 自己搭建一个NFS服务器, 并将NFS服务器上的某个文件夹mount到pod中:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">...</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">mongodb-data</span></span><br><span class="line">      <span class="attr">nfs:</span></span><br><span class="line">        <span class="attr">server:</span> <span class="number">1.2</span><span class="number">.3</span><span class="number">.4</span></span><br><span class="line">        <span class="attr">path:</span> <span class="string">/some/path</span> </span><br></pre></td></tr></table></figure>
<p>除此之外, k8s还支持其他persistent storage:</p>
<ul>
<li>iscsi: ISCSI disk</li>
<li>glusterfs: GlusterFS Mount</li>
<li>rbd: RADOS Block Device</li>
<li>flexVolume: 自定义驱动的存储</li>
<li>cinder: Cinder block storage device</li>
<li>cephfs: Ceph File System</li>
<li>flocker: Flocker container data management platform</li>
<li>fc: Fibre Channel storage device</li>
</ul>
<h2 id="5-Decouple-Pods-from-the-Underlying-Storage-Technology"><a href="#5-Decouple-Pods-from-the-Underlying-Storage-Technology" class="headerlink" title="5. Decouple Pods from the Underlying Storage Technology"></a>5. Decouple Pods from the Underlying Storage Technology</h2><p>上述所有volume都解决了persistent storage问题, 但每一个volume都与平台或底层技术绑定. 以GCE persistent disk为例, 若开发者决定将k8s cluster从GCP迁移到AWS, 则需重写每一个pod. 因此需要一种方法, 既提供persistent storage, 又不绑定某个云服务提供商或存储技术. 理想状态下, 开发者不需要了解每个volume的底层配置, 所有volume的配置应由cluster管理员负责. K8s为此提供PV(<strong>PersistentVolume</strong>)和PVC(<strong>PersistentVolumeClaim</strong>)来方便volume的配置与管理.<br>简单来说, PV是对存储资源的一种抽象, 通常由cluster管理员手动或自动创建; PVC则是pod对存储资源的请求声明, 从而分离存储资源的申请和使用: </p>
<ul>
<li>cluster将存储资源包装成一个PV</li>
<li>开发者在PVC中说明所需的存储大小和访问模式, k8s会找到最合适的PV并将绑定给该PVC</li>
</ul>
<p><img src="/images/Kubernetes/vol-5-1.png" alt="PersistentVolumes are provisioned by cluster admins and consumed by pods through PersistentVolumeClaims"></p>
<h3 id="5-1-Claim-a-PersistentVolume"><a href="#5-1-Claim-a-PersistentVolume" class="headerlink" title="5.1 Claim a PersistentVolume"></a>5.1 Claim a PersistentVolume</h3><p>以GCP为例, cluster管理员需要创建一个PV, 其存储依赖于GCE persistent disk:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolume</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">mongodb-pv</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">capacity:</span></span><br><span class="line">    <span class="attr">storage:</span> <span class="string">1Gi</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">ReadWriteOnce</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">ReadOnlyMany</span></span><br><span class="line">  <span class="attr">persistentVolumeReclaimPolicy:</span> <span class="string">Retain</span></span><br><span class="line">  <span class="attr">gcePersistentDisk:</span></span><br><span class="line">    <span class="attr">pdName:</span> <span class="string">mongodb</span></span><br><span class="line">    <span class="attr">fsType:</span> <span class="string">ext4</span> </span><br></pre></td></tr></table></figure>
<p>该PV的配置如下:</p>
<ul>
<li>PV的存储空间为1Gb</li>
<li>由于<code>persistentVolumeReclaimPolicy</code>为<code>Retain</code>, 因此即便PVC解绑该PV, 该PV也不会被删除</li>
<li><code>gcePersistentDisk</code>的配置与之前相同</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ kubectl get pv</span><br><span class="line">NAME       CAPACITY RECLAIMPOLICY ACCESSMODES STATUS    CLAIM</span><br><span class="line">mongodb-pv 1Gi      Retain        RWO,ROX     Available </span><br></pre></td></tr></table></figure>
<p>由于新创建的PV还未与任何PVC绑定, 因此<code>mongodb-pv</code>的状态为<code>Available</code>, 而不是<code>Bound</code>. PV不属于某个namespace, 只与cluster绑定, 但PVC必须属于某个namespace, 只有pod与PVC处于同一namespace时才能在pod中使用PVC.<br><img src="/images/Kubernetes/vol-5-2.png" alt="PV doesn’t belong to any namespace, unlike pods and PVC"></p>
<h3 id="5-2-Claiming-a-PersistentVolume-by-creating-a-PersistentVolumeClaim"><a href="#5-2-Claiming-a-PersistentVolume-by-creating-a-PersistentVolumeClaim" class="headerlink" title="5.2 Claiming a PersistentVolume by creating a PersistentVolumeClaim"></a>5.2 Claiming a PersistentVolume by creating a PersistentVolumeClaim</h3><p>假设开发者需要一个1Gb大小的persistent storage, 可创建一个PVC资源:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolumeClaim</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">mongodb-pvc</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">    <span class="attr">requests:</span></span><br><span class="line">      <span class="attr">storage:</span> <span class="string">1Gi</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">ReadWriteOnce</span></span><br><span class="line">  <span class="attr">storageClassName:</span> <span class="string">&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<p>K8s会为该PVC寻找一个合适的PV:</p>
<ul>
<li>PV的存储大小必须大于PVC的存储需求</li>
<li>PV的访问模式必须满足PVC的访问需求</li>
</ul>
<p>通过以下命令可显示所有PVC:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ kubectl get pvc</span><br><span class="line">NAME        STATUS VOLUME     CAPACITY ACCESSMODES AGE</span><br><span class="line">mongodb-pvc Bound  mongodb-pv 1Gi      RWO,ROX     3s</span><br></pre></td></tr></table></figure>
<p>K8s为存储空间提供了三种访问模式:</p>
<ol>
<li>RWO(ReadWriteOnce): 只允许一个node读取或写入该存储资源</li>
<li>ROX(ReadOnlyMany): 允许多个node读取该存储资源</li>
<li>RWX(ReadWriteMany): 允许多个node读取或写入该存储资源</li>
</ol>
<p>需要注意的是, 上述访问模式与node的数量有关, 不与pod数量相关. 以下是<code>mongodb-pv</code>与PVC绑定后的状态:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ kubectl get pv</span><br><span class="line">NAME       CAPACITY ACCESSMODES STATUS CLAIM               AGE</span><br><span class="line">mongodb-pv 1Gi      RWO,ROX     Bound  default/mongodb-pvc 1m</span><br></pre></td></tr></table></figure>

<h3 id="5-3-Use-a-PersistentVolumeClaim"><a href="#5-3-Use-a-PersistentVolumeClaim" class="headerlink" title="5.3 Use a PersistentVolumeClaim"></a>5.3 Use a PersistentVolumeClaim</h3><p>PVC与PV绑定后就可以在pod中使用PVC:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">mongodb</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">containers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">image:</span> <span class="string">mongo</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">mongodb</span></span><br><span class="line">    <span class="attr">volumeMounts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">mongodb-data</span></span><br><span class="line">      <span class="attr">mountPath:</span> <span class="string">/data/db</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">containerPort:</span> <span class="number">27017</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">mongodb-data</span></span><br><span class="line">    <span class="attr">persistentVolumeClaim:</span></span><br><span class="line">    <span class="attr">claimName:</span> <span class="string">mongodb-pvc</span> </span><br></pre></td></tr></table></figure>
<p>虽然需要一些额外步骤来使用PVC和PV, 但开发者从此不必知道volume的底层技术和存储位置, 管理员将volume转移到其他平台或使用其他技术时也不必通知开发者.<br><img src="/images/Kubernetes/vol-5-3.png" alt="PV doesn’t belong to any namespace, unlike pods and PVC"></p>
<h3 id="5-4-Recycle-PersistentVolume"><a href="#5-4-Recycle-PersistentVolume" class="headerlink" title="5.4 Recycle PersistentVolume"></a>5.4 Recycle PersistentVolume</h3><p>删除PVC后, PV的状态会从<code>Bound</code>变为<code>Released</code>, 而不是<code>Available</code>. 若新的PVC尝试绑定该PV, 该PVC的状态会一直为<code>Pending</code>. K8s之所以不允许PV重新绑定, 是为了保证PV中的数据得到合适的处理(清理或再利用):</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ kubectl delete pod mongodb</span><br><span class="line">pod <span class="string">&quot;mongodb&quot;</span> deleted</span><br><span class="line">$ kubectl delete pvc mongodb-pvc</span><br><span class="line">persistentvolumeclaim <span class="string">&quot;mongodb-pvc&quot;</span> deleted</span><br><span class="line"></span><br><span class="line">$ kubectl get pv</span><br><span class="line">NAME       CAPACITY ACCESSMODES STATUS   CLAIM               REASON AGE</span><br><span class="line">mongodb-pv 1Gi      RWO,ROX     Released default/mongodb-pvc        5m</span><br></pre></td></tr></table></figure>
<p>两种回收PV的方式:</p>
<ul>
<li>手动回收: 将<code>persistentVolumeReclaimPolicy</code>设为<code>Retain</code>后, PV只能被删除后重新创建才能与新的PVC绑定</li>
<li>自动回收: 将<code>persistentVolumeReclaimPolicy</code>设为<code>Recycle</code>或<code>Delete</code>, PV与PVC解绑后自动变为<code>Available</code>状态. <code>Recycle</code>表示PV将保留数据, <code>Delete</code>表示PV将删除所有数据.<br><img src="/images/Kubernetes/vol-5-4.png" alt="PV doesn’t belong to any namespace, unlike pods and PVC"></li>
</ul>
<h2 id="6-Dynamic-Provisioning-of-PersistentVolume"><a href="#6-Dynamic-Provisioning-of-PersistentVolume" class="headerlink" title="6. Dynamic Provisioning of PersistentVolume"></a>6. Dynamic Provisioning of PersistentVolume</h2><p>PV和PVC让存储资源的申请和获取分离. 开发者只需在PVC中说明所需存储空间和访问模式即可获取存储资源; 但cluster管理员面临一个难题: 随着cluster中的pod数量不断增加, 其申请的存储资源也越来越多, 需要cluster管理员不断创建PV. K8s为此提供了<strong>StorageClass</strong>来实现对PV的动态供给. StorageClass会根据不同的PVC创建对应的PV, 因此cluster管理员不必手动创建每个PV. StorageClass与PV相同, 都不属于某个namespace, 只属于cluster.</p>
<h3 id="6-1-Define-a-StorageClass"><a href="#6-1-Define-a-StorageClass" class="headerlink" title="6.1 Define a StorageClass"></a>6.1 Define a StorageClass</h3><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">storage.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StorageClass</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">fast</span></span><br><span class="line"><span class="attr">provisioner:</span> <span class="string">kubernetes.io/gce-pd</span></span><br><span class="line"><span class="attr">parameters:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">pd-ssd</span></span><br><span class="line">  <span class="attr">zone:</span> <span class="string">europe-west1-b</span> </span><br></pre></td></tr></table></figure>
<p>上述YAML文件创建了一个StorageClass, 其包含一个provisioner, 负责生成PV. K8s内置了绝大多数云服务提供商的provisioner, cluster管理员也可以自定义provisioner. 本例中使用GCE的persistent disk provisioner, 每当PVC需要PV时, provisioner会创建一个符合要求的PV.</p>
<h3 id="6-2-Request-the-StorageClass-in-a-PersistentVolumeClaim"><a href="#6-2-Request-the-StorageClass-in-a-PersistentVolumeClaim" class="headerlink" title="6.2 Request the StorageClass in a PersistentVolumeClaim"></a>6.2 Request the StorageClass in a PersistentVolumeClaim</h3><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolumeClaim</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">mongodb-pvc</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">storageClassName:</span> <span class="string">fast</span></span><br><span class="line">  <span class="attr">resources:</span></span><br><span class="line">    <span class="attr">requests:</span></span><br><span class="line">      <span class="attr">storage:</span> <span class="string">100Mi</span></span><br><span class="line">  <span class="attr">accessModes:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">ReadWriteOnce</span></span><br></pre></td></tr></table></figure>
<p>运行<code>kubectl get pvc</code>时可看到, StorageClass自动创建了一个名为<code>pvc-1e6bc048</code>的PV, 且PVC成功与该PV绑定:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ kubectl get pvc mongodb-pvc</span><br><span class="line">NAME        STATUS VOLUME       CAPACITY ACCESSMODES STORAGECLASS</span><br><span class="line">mongodb-pvc Bound  pvc-1e6bc048 1Gi      RWO         fast</span><br><span class="line"></span><br><span class="line">$ kubectl get pv</span><br><span class="line">NAME         CAPACITY ACCESSMODES RECLAIMPOLICY STATUS  STORAGECLASS</span><br><span class="line">pvc-1e6bc048 1Gi      RWO         Delete        Bound   fast</span><br></pre></td></tr></table></figure>
<p>StorageClass不仅自动生成了PV, 还在GCP中自动申请persistent disk.</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ gcloud compute disks list</span><br><span class="line">NAME                        ZONE           SIZE_GB TYPE        STATUS</span><br><span class="line">gke-kubia-dyn-pvc-1e6bc048  europe-west1-d 1       pd-ssd      READY</span><br><span class="line">gke-kubia-default-pool-71df europe-west1-d 100     pd-standard READY</span><br><span class="line">gke-kubia-default-pool-79cd europe-west1-d 100     pd-standard READY</span><br><span class="line">gke-kubia-default-pool-blc4 europe-west1-d 100     pd-standard READY</span><br><span class="line">mongodb                     europe-west1-d 1       pd-standard READY</span><br></pre></td></tr></table></figure>
<p>除了帮助cluster管理员摆脱重复创建PV的繁琐工作, StorageClass还可以实现PVC的跨cluster: 只要所有cluser上都部署相同的StorageClass, 那么就可以在所有cluster中使用相同PVC.</p>
<h3 id="6-3-Dynamic-provisioning-without-specifying-a-StorageClass"><a href="#6-3-Dynamic-provisioning-without-specifying-a-StorageClass" class="headerlink" title="6.3 Dynamic provisioning without specifying a StorageClass"></a>6.3 Dynamic provisioning without specifying a StorageClass</h3><p>除了自定义的StorageClass, GKE还提供了默认StorageClass:</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ kubectl get sc</span><br><span class="line">NAME               TYPE</span><br><span class="line">fast               kubernetes.io/gce-pd</span><br><span class="line">standard (default) kubernetes.io/gce-pd</span><br></pre></td></tr></table></figure>
<p>GKE中, 默认StorageClass名为<code>standard</code>. 若PVC没有指定任何StorageClass, 将会使用该StorageClass. </p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ kubectl get sc standard -o yaml</span><br><span class="line">apiVersion: storage.k8s.io/v1</span><br><span class="line">kind: StorageClass</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    storageclass.beta.kubernetes.io/is-default-class: <span class="string">&quot;true&quot;</span></span><br><span class="line">  creationTimestamp: 2017-05-16T15:24:11Z</span><br><span class="line">  labels:</span><br><span class="line">    addonmanager.kubernetes.io/mode: EnsureExists</span><br><span class="line">    kubernetes.io/cluster-service: <span class="string">&quot;true&quot;</span></span><br><span class="line">  name: standard</span><br><span class="line">  resourceVersion: <span class="string">&quot;180&quot;</span></span><br><span class="line">  selfLink: /apis/storage.k8s.io/v1/storageclassesstandard</span><br><span class="line">  uid: b6498511-3a4b-11e7-ba2c-42010a840014</span><br><span class="line">parameters:</span><br><span class="line">  <span class="built_in">type</span>: pd-standard</span><br><span class="line">provisioner: kubernetes.io/gce-pd </span><br></pre></td></tr></table></figure>
<p>需要注意的是, 不同云计算平台上的默认StorageClass可能拥有不同的provisioner, GKE使用<code>kubernetes.io/gce-pd</code>.</p>
<p>总结一下, PV&#x2F;PVC模式下的volume分为两种:</p>
<ul>
<li>pre-provisioned PV: cluster管理员创建PV, k8s根据PVC的存储需求匹配一个合适的PV</li>
<li>dynamic provisioning PV: cluster管理员创建StorageClass, StorageClass根据PVC的存储需求创建一个合适的PV</li>
</ul>
<p>使用pre-provisioned PV时, 需要在PVC中标注<code>storageClassName: &quot;&quot;</code>, 这样k8s就不会使用StorageClass, 而去寻找合适的PV.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolumeClaim</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="string">...</span></span><br><span class="line">  <span class="attr">storageClassName:</span> <span class="string">&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<p>以下为dynamically provisoneing PV的流程图:<br><img src="/images/Kubernetes/vol-6-1.png" alt="The complete picture of dynamic provisioning of PersistentVolumes"></p>

    </div>

    <footer class="post-footer">
      
      <div class="post-tags">
        
          <a href="/tags/K8s/">K8s</a>
        
      </div>
      

      
      
  <nav class="post-nav">
    
      <a class="prev" href="/p/95.html">
        <i class="icon-left"></i>
        <span class="prev-text nav-default">ConfigMap and Secret</span>
        <span class="prev-text nav-mobile">Prev</span>
      </a>
    
    
      <a class="next" href="/p/1936.html">
        <span class="next-text nav-default">Services</span>
        <span class="prev-text nav-mobile">Next</span>
        <i class="icon-right"></i>
      </a>
    
  </nav>

      
    </footer>
  </article>

  </div>
  
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js?config=TeX-MML-AM_CHTML"></script>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    showProcessingMessages: true,
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        processEscapes: false,
        skipTags: ["script","noscript","style","textarea"]
    },
    TeX: {
        Macros:{
            Arr: ["\\{ #1 \\}", 1],
            fi: "{f\\,\\!_i}",
            SS: ["{#1\\:\\!_#2}",2],
            SUBx: ["{\\:\\!_#1}",1],
            EXPx: ["{\\;\\!^#1}",1],
            Ss: ["{#1\\,\\!_#2}",2],
            subx: ["{\\,\\!_#1}",1]
        }
    }
});
</script>


      </div>
    </div>

    
<script type="text/javascript">
  var disqus_shortname = 'zaf1ro';
  var disqus_identifier = 'p/f56f.html';
  var disqus_title = "Volumes";

  var disqus = {
    load : function disqus(){
        if(typeof DISQUS !== 'object') {
          (function () {
          var s = document.createElement('script'); s.async = true;
          s.type = 'text/javascript';
          s.src = '//' + disqus_shortname + '.disqus.com/embed.js';
          (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
          }());
          $('#load-disqus').remove(); ///加载后移除按钮
        }
    }
  }

  
    var disqus_config = function () {
        this.page.url = disqus_url;
        this.page.identifier = disqus_identifier;
        this.page.title = disqus_title;
    };
  

</script>



    




  
    <script type="text/javascript" src="/lib/jquery/jquery-3.6.0.min.js"></script>
  

  

    
    <script type="text/javascript">
(function(){"use strict";var Theme={};Theme.backToTop={register:function(){var $backToTop=$('#back-to-top');$(window).scroll(function(){if($(window).scrollTop()>100){$backToTop.fadeIn(1000)}else{$backToTop.fadeOut(1000)}});$backToTop.click(function(){$('body').animate({scrollTop:0})})}};Theme.fancybox={register:function(){if($.fancybox){$('.post').each(function(){$(this).find('img').each(function(){$(this).wrap('<a class="fancybox" href="'+this.src+'" title="'+this.alt+'"></a>')})});$('.fancybox').fancybox({openEffect:'elastic',closeEffect:'elastic'})}}};this.Theme=Theme}.call(this));
</script>

<script type="text/javascript">
$(document).ready(function(){if(themeConfig.fancybox.enable){Theme.fancybox.register()}Theme.backToTop.register()});
</script>
    
<script type="text/javascript">
var themeConfig = {
  fancybox: {
    enable: false
  },
};
</script>

    <script>
    $('table').wrap('<div style="overflow-x: auto;"></div>');
</script>
    
    <script>
$(document).ready(function () {
    $('#sidebarCollapse').on('click', function(){
        $('#sidebar').toggleClass('active');
    });

    $('#toc ol li a').on('click', function(){
        $('#sidebar').toggleClass('active');
    });
});
</script>
  </body>
</html>
